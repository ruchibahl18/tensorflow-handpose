<html>
	<head>
		<style>
			#videoElement {
				width: 600px;
				height: 400px;
				background-color: black;
				display: none;
			}
		</style>
	</head>
	
	<body>
		<video autoplay='true' id='videoElement'></video>
		<canvas id='canvas' width='600px' height='400px'></canvas>
	<body>
	<!-- Require the peer dependencies of handpose. -->
	<script src="https://unpkg.com/@tensorflow/tfjs-core@2.1.0/dist/tf-core.js"></script>
	<script src="https://unpkg.com/@tensorflow/tfjs-converter@2.1.0/dist/tf-converter.js"></script>

	<!-- You must explicitly require a TF.js backend if you're not using the tfs union bundle. -->
	<script src="https://unpkg.com/@tensorflow/tfjs-backend-webgl@2.1.0/dist/tf-backend-webgl.js"></script>
	<!-- Alternatively you can use the WASM backend: <script src="https://unpkg.com/@tensorflow/tfjs-backend-wasm@2.1.0/dist/tf-backend-wasm.js"></script> -->

	<script src="https://unpkg.com/@tensorflow-models/handpose@0.0.6/dist/handpose.js"></script>
	
	<script>
		let fingerLookupIndices = {
		  thumb: [0, 1, 2, 3, 4],
		  indexFinger: [0, 5, 6, 7, 8],
		  middleFinger: [0, 9, 10, 11, 12],
		  ringFinger: [0, 13, 14, 15, 16],
		  pinky: [0, 17, 18, 19, 20]
		};
		function drawPoint(y, x, r) {
		  ctx.beginPath();
		  ctx.arc(x, y, r, 0, 2 * Math.PI);
		  ctx.fill();
		}

		function drawKeypoints(keypoints) {
		  const keypointsArray = keypoints;

		  for (let i = 0; i < keypointsArray.length; i++) {
			const y = keypointsArray[i][0];
			const x = keypointsArray[i][1];
			drawPoint(x - 2, y - 2, 3);
		  }

		  const fingers = Object.keys(fingerLookupIndices);
		  for (let i = 0; i < fingers.length; i++) {
			const finger = fingers[i];
			const points = fingerLookupIndices[finger].map(idx => keypoints[idx]);
			drawPath(points, false);
		  }
		}

		function drawPath(points, closePath) {
		  const region = new Path2D();
		  region.moveTo(points[0][0], points[0][1]);
		  for (let i = 1; i < points.length; i++) {
			const point = points[i];
			region.lineTo(point[0], point[1]);
		  }

		  if (closePath) {
			region.closePath();
		  }
		  ctx.stroke(region);
		}
		let video = document.getElementById('videoElement');
		let canvas = document.getElementById('canvas');
		let ctx = canvas.getContext('2d');
		let model;
		const setUpCamera = () => {
			if(navigator.mediaDevices.getUserMedia) {
				navigator.mediaDevices.getUserMedia({video: true})
					.then(function(stream) {
						video.srcObject = stream;
					})
					.catch(function(err) {
						console.log(err);
					});
			}
		}
		const detectHandPoses = async () => {
				const prediction = await model.estimateHands(video);
				ctx.drawImage(video,0,0,600,400);
				ctx.beginPath();
				ctx.strokeStyle='blue';
				ctx.lineWidth = '4';
				//console.log(prediction);
				prediction.forEach((pred) => {
					const result = pred.landmarks;
					const annotations = pred.annotations;
					drawKeypoints(result, annotations);
				});
		}
		setUpCamera();
		video.addEventListener("loadeddata", async () => {
			model = await handpose.load();
			setInterval(detectHandPoses,100);
		});
	</script>
</html>